{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to demonstrate the 2-stage Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection  import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_data_f = \"parsed_drug.csv\"\n",
    "train_data_f = \"parsed_drug_four_cat.csv\"\n",
    "#test_data_f = \"test_binary.csv\"\n",
    "test_data_f = \"test_four_cat.csv\"\n",
    "df = pd.read_csv(train_data_f, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df.head()\n",
    "#print(df.loc[df['ddi_label'] == 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's learn more about our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of drug pairs with no affect on each other:  (20532, 7)\n",
      "Number of drug pairs that do affect each other:  (3709, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of drug pairs with no affect on each other: \", df.loc[df['ddi_label'] == 0].shape)\n",
    "print(\"Number of drug pairs that do affect each other: \", df.loc[df['ddi_label'] >= 1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is very uneven. We might be overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training and development sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_train_dev_test(df):\n",
    "    random_index = np.random.permutation(df.index)\n",
    "    df_shuffled = df.ix[random_index, ['drug1', 'drug2', 'sentence_text', 'ddi_label']]\n",
    "    df_shuffled.reset_index(drop=True, inplace=True)\n",
    "    rows, columns =  df_shuffled.shape\n",
    "    train_size = round(rows*.6)\n",
    "    dev_size   = round(rows*.4)\n",
    "    df_train = df_shuffled.loc[:train_size]\n",
    "    df_dev = df_shuffled.loc[train_size:dev_size+train_size].reset_index(drop=True)\n",
    "    return df_train, df_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train, df_dev = create_train_dev_test(df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in test set (5265, 4)\n",
      "Number of ddis that do not affect each other (4381, 4)\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(test_data_f, low_memory=False)\n",
    "df_test = df_test[['drug1', 'drug2', 'sentence_text', 'ddi_label']]\n",
    "print(\"Number of rows in test set\", df_test.shape)\n",
    "print(\"Number of ddis that do not affect each other\", df_test.loc[df_test.ddi_label == 0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_tfidf_tr_dev_test(label, df_train, df_dev, df_test):\n",
    "    '''\n",
    "    Creates all featuresets for train, dev, and test.\n",
    "    @param feature_func the function to apply to the sentences to extract features\n",
    "    @param label some label to give to this feature method, aids documentation only but\n",
    "        does not affect the code.\n",
    "        \n",
    "        returns arrays for the train, dev, and test featuresets\n",
    "    '''\n",
    "    vec = TfidfVectorizer(ngram_range=(1, 2), max_df=0.8, max_features=1000)\n",
    "    arr_train_feature_sparse = vec.fit_transform(df_train['sentence_text'])\n",
    "    arr_train_feature = arr_train_feature_sparse.toarray()\n",
    "    arr_train_feature.shape\n",
    "    \n",
    "    arr_dev_feature_sparse = vec.transform(df_dev[\"sentence_text\"])\n",
    "    arr_dev_feature = arr_dev_feature_sparse.toarray()\n",
    "    arr_dev_feature.shape\n",
    "    \n",
    "    arr_test_feature_sparse = vec.transform(df_test[\"sentence_text\"])\n",
    "    arr_test_feature = arr_test_feature_sparse.toarray()\n",
    "    arr_test_feature.shape\n",
    "    \n",
    "    return arr_train_feature, arr_dev_feature, arr_test_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_tfidf_tr_dev_test_simple(label):\n",
    "    '''\n",
    "    Creates all featuresets for train, dev, and test.\n",
    "    @param feature_func the function to apply to the sentences to extract features\n",
    "    @param label some label to give to this feature method, aids documentation only but\n",
    "        does not affect the code.\n",
    "        \n",
    "        returns arrays for the train, dev, and test featuresets\n",
    "    '''\n",
    "    vec = TfidfVectorizer(ngram_range=(1, 2), max_df=0.8, max_features=1000)\n",
    "    arr_train_feature_sparse = vec.fit_transform(df_train['sentence_text'])\n",
    "    arr_train_feature = arr_train_feature_sparse.toarray()\n",
    "    arr_train_feature.shape\n",
    "    \n",
    "    arr_dev_feature_sparse = vec.transform(df_dev[\"sentence_text\"])\n",
    "    arr_dev_feature = arr_dev_feature_sparse.toarray()\n",
    "    arr_dev_feature.shape\n",
    "    \n",
    "    arr_test_feature_sparse = vec.transform(df_test[\"sentence_text\"])\n",
    "    arr_test_feature = arr_test_feature_sparse.toarray()\n",
    "    arr_test_feature.shape\n",
    "    \n",
    "    return arr_train_feature, arr_dev_feature, arr_test_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_tfidf_tr_dev(label, df_train, df_dev):\n",
    "    '''\n",
    "    Creates all featuresets for train and dev\n",
    "    @param feature_func the function to apply to the sentences to extract features\n",
    "    @param label some label to give to this feature method, aids documentation only but\n",
    "        does not affect the code.\n",
    "        \n",
    "        returns arrays for the train and dev featuresets\n",
    "    '''\n",
    "    vec = TfidfVectorizer(ngram_range=(1, 2), max_df=0.8, max_features=1000)\n",
    "    arr_train_feature_sparse = vec.fit_transform(df_train['sentence_text'])\n",
    "    arr_train_feature = arr_train_feature_sparse.toarray()\n",
    "    arr_train_feature.shape\n",
    "    \n",
    "    arr_dev_feature_sparse = vec.transform(df_dev[\"sentence_text\"])\n",
    "    arr_dev_feature = arr_dev_feature_sparse.toarray()\n",
    "    arr_dev_feature.shape\n",
    "    \n",
    "    feature_names = vec.get_feature_names()\n",
    "    \n",
    "    return arr_train_feature, arr_dev_feature, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_tfidf_test(label, df_test, dev_feature_names):\n",
    "    '''\n",
    "    Creates featureset for test\n",
    "    @param feature_func the function to apply to the sentences to extract features\n",
    "    @param label some label to give to this feature method, aids documentation only but\n",
    "        does not affect the code.\n",
    "        \n",
    "        returns array for the test featureset\n",
    "    '''\n",
    "    vec = TfidfVectorizer(ngram_range=(1, 2), max_df=0.8, max_features=1000,\n",
    "                         vocabulary=dev_feature_names)\n",
    "    arr_test_feature_sparse = vec.fit_transform(df_test[\"sentence_text\"])\n",
    "    arr_test_feature = arr_test_feature_sparse.toarray()\n",
    "    arr_test_feature.shape\n",
    "    \n",
    "    return arr_test_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Naive Bayes - single stage classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating featuresets...\n",
      "Created featuresets\n",
      "Applying ML model...\n",
      "Applying ML model to test data...\n",
      "Accuracy:\n",
      "0.727310231023\n",
      "[ 0.83481639  0.27401575  0.13033175  0.31279621  0.07531381]\n",
      "neg (0) pos(1) 2 3 4\n",
      "[ 0.86119874  0.26785714  0.05442177  0.2344086   0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vikram/anaconda/envs/d3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('Creating featuresets...')\n",
    "tr, dev, test = create_tfidf_tr_dev_test_simple('tfidf')\n",
    "print('Created featuresets')\n",
    "print('Applying ML model...')\n",
    "nb = MultinomialNB()\n",
    "nb_model_dev = nb.fit(tr, df_train.ddi_label)\n",
    "nb_pred_dev = nb_model_dev.predict(dev)\n",
    "print(\"Applying ML model to test data...\")\n",
    "nb_pred_test = nb_model_dev.predict(test)\n",
    "from sklearn.metrics import f1_score\n",
    "# before I used the binary predictions - 0 or 1\n",
    "print('Accuracy:')\n",
    "print(accuracy_score(df_dev.ddi_label, nb_pred_dev))\n",
    "print(f1_score(df_dev.ddi_label, nb_pred_dev, average=None, pos_label = 1))\n",
    "print('neg (0)', 'pos(1)', '2','3','4')\n",
    "print(f1_score(df_test.ddi_label, nb_pred_test, average=None, pos_label = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Models - 1st stage classification\n",
    "Develop the dev model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_train.ddi_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr_train_feature, arr_dev_feature, arr_test_feature = create_tfidf_tr_dev_test('tdidf',\n",
    "                                                            df_train, df_dev, df_test)\n",
    "nb = MultinomialNB()\n",
    "\n",
    "nb_model = nb.fit(arr_train_feature, df_train.ddi_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_predictions = nb_model.predict(arr_dev_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72731023102310233"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df_dev.ddi_label, nb_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 4, ..., 0, 0, 4])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.83481639  0.27401575  0.13033175  0.31279621  0.07531381]\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(df_dev.ddi_label, nb_predictions,average=None, pos_label = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model for test data\n",
    "Use the dev model to predict the ddi_labels in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_predictions_test = nb_model.predict(arr_test_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the DDI labels to an intermediary dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "interaction_data_test = list(zip(df_test['sentence_text'], nb_predictions_test))\n",
    "interaction_data_test = [(sent,interaction) for (sent,interaction) in interaction_data_test\n",
    "                            if interaction >= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.86119874  0.26785714  0.05442177  0.2344086   0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vikram/anaconda/envs/d3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(df_test.ddi_label, nb_predictions_test, average=None, pos_label = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the positive-interaction results to a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('positive_interactions.csv', 'w') as fout:\n",
    "    fout.write('sentence_text,Category\\n')\n",
    "    for doc, category in zip(df_dev['sentence_text'], nb_predictions):\n",
    "        if category >= 1:\n",
    "            fout.write(\"\\\"\" + doc + '\\\",' + str(category) + '\\n')\n",
    "interaction_data = list(zip(df_dev['sentence_text'], nb_predictions))\n",
    "interaction_data = [(sent,interaction) for (sent,interaction) in interaction_data \n",
    "                    if interaction >= 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redo the pipeline to further classify the positive interaction into the 4 categories (1,2,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.994805194805\n",
      "1157\n",
      "770\n",
      "[ 0.98373984  0.99285714  0.99714286  1.        ]\n"
     ]
    }
   ],
   "source": [
    "train_data_f_2nd = \"positive_interactions.csv\"\n",
    "#df_2nd = pd.read_csv(train_data_f_2nd, low_memory=False, quotechar=\"\\\"\")\n",
    "df_2nd = pd.DataFrame(interaction_data, columns=['sentence_text', 'ddi_label'])\n",
    "df_train_2nd, df_dev_2nd = create_train_dev_test(df_2nd);\n",
    "arr_train_feature_2nd, arr_dev_feature_2nd, feature_names = create_tfidf_tr_dev('tdidf', \n",
    "                                                                df_train_2nd,\n",
    "                                                                df_dev_2nd)\n",
    "nb_2nd = MultinomialNB()\n",
    "\n",
    "nb_model_2nd = nb_2nd.fit(arr_train_feature_2nd, df_train_2nd.ddi_label)\n",
    "nb_predictions_2nd = nb_model_2nd.predict(arr_dev_feature_2nd)\n",
    "print(accuracy_score(df_dev_2nd.ddi_label, nb_predictions_2nd))\n",
    "print(len(df_train_2nd))\n",
    "print(len(df_dev_2nd))\n",
    "print(f1_score(df_dev_2nd.ddi_label, nb_predictions_2nd, average=None, pos_label = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Need to do 2-stage classification on test data too\n",
    "I use the dev feature names and the dev model to predict the 2nd stage classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.998701298701\n",
      "770\n",
      "0\n",
      "770\n",
      "0.998364753276\n"
     ]
    }
   ],
   "source": [
    "#train_data_f_2nd = \"positive_interactions.csv\"\n",
    "#df_2nd = pd.read_csv(train_data_f_2nd, low_memory=False, quotechar=\"\\\"\")\n",
    "df_test_2nd = pd.DataFrame(interaction_data_test, columns=['sentence_text', 'ddi_label'])\n",
    "\n",
    "#df_train_2nd, df_dev_2nd = create_train_dev_test(df_2nd);\n",
    "\n",
    "arr_test_feature_2nd = create_tfidf_test('tdidf', df_test_2nd, feature_names)\n",
    "#nb_2nd = MultinomialNB()\n",
    "\n",
    "#nb_model_2nd = nb_2nd.fit(arr_train_feature_2nd, df_train_2nd.ddi_label)\n",
    "# Using the fitted model from the dev training set:\n",
    "nb_test_predictions_2nd = nb_model_2nd.predict(arr_test_feature_2nd)\n",
    "print(accuracy_score(df_test_2nd.ddi_label, nb_test_predictions_2nd))\n",
    "print(len(df_test_2nd))\n",
    "print(len(nb_test_predictions_2nd))\n",
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(df_test_2nd.ddi_label, \n",
    "               nb_test_predictions_2nd, average='macro', pos_label = 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The f-score is really high because there is very little variation in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's create the new dataframe with our predictions! Then I'll change the values of the interactions in two stages. Finally, I'll compute the f-score using the original test set and the new predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prepare_test_for_2nd_pass = list(zip(df_test['sentence_text'], nb_predictions_test))\n",
    "df_test_prepare_for_2nd = pd.DataFrame(prepare_test_for_2nd_pass, columns=['sentence_text',\n",
    "                                                                    'ddi_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test_after_2nd_pass = df_test_prepare_for_2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_after_2nd_pass = list(zip(df_test_2nd['sentence_text'],nb_test_predictions_2nd))\n",
    "for sentence, interaction in test_after_2nd_pass:\n",
    "    df_test_after_2nd_pass.loc[(df_test_after_2nd_pass.sentence_text == sentence),\n",
    "                              'ddi_label'] = interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.86119874  0.26268657  0.05442177  0.23415682  0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vikram/anaconda/envs/d3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(df_test.ddi_label, df_test_after_2nd_pass.ddi_label, average=None, pos_label = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Summary of results:\n",
    "The results after the 2-stage classification -- values went down slightly:\n",
    "\n",
    "1-stage: [ 0.86119874  0.26785714  0.05442177  0.2344086   0.        ]\n",
    "\n",
    "2-stage: [ 0.86119874  0.26268657  0.05442177  0.23415682  0.        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the f-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.90536023  0.19588639]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(df_dev.ddi_label, knn_pred_dev, average=None, pos_label = 1))\n",
    "#print(f1_score(df_test.ddi_label, knn_pred_test, average=None, pos_label = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
